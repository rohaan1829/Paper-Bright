{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Brightening the background without hurting the content."
      ],
      "metadata": {
        "id": "VTYx1SkR3Pr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sharpen the blurry Text/Image"
      ],
      "metadata": {
        "id": "wY_0N_Nr2xtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ----------- Sharpen and Enhance the JPG Image -----------\n",
        "def sharpen_image(image_path, output_path='sharpened_result.jpg'):\n",
        "    # Load the image\n",
        "    image = cv2.imread(\"Paste Path here\")\n",
        "\n",
        "    # Step 1: Apply Gaussian blur (used for sharpening)\n",
        "    blurred = cv2.GaussianBlur(image, (0, 0), sigmaX=3)\n",
        "\n",
        "    # Step 2: Sharpen using unsharp masking\n",
        "    sharpened = cv2.addWeighted(image, 1.7, blurred, -0.7, 0)\n",
        "\n",
        "    # Step 3: Convert to LAB color space to enhance contrast\n",
        "    lab = cv2.cvtColor(sharpened, cv2.COLOR_BGR2LAB)\n",
        "    l_channel, a, b = cv2.split(lab)\n",
        "\n",
        "    # Apply CLAHE to the L-channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l_channel)\n",
        "    merged_lab = cv2.merge((cl, a, b))\n",
        "\n",
        "    # Convert back to BGR\n",
        "    final_image = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Step 4: Slight denoising (optional but helpful for OCR appearance)\n",
        "    denoised = cv2.fastNlMeansDenoisingColored(final_image, None, 10, 10, 7, 21)\n",
        "\n",
        "    # Save the final sharpened image\n",
        "    cv2.imwrite(output_path, denoised)\n",
        "    print(f\"[+] Sharpened image saved as: {output_path}\")\n",
        "\n",
        "# ----------- Usage -----------\n",
        "# Replace with your actual JPG filename\n",
        "sharpen_image(\"your_result_card.jpg\")\n"
      ],
      "metadata": {
        "id": "gpdG5u9N2nbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#clears the white background Excluding the Image(define coordinates)"
      ],
      "metadata": {
        "id": "1usvaqQ026FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def whiten_background_with_exclusion(image_path, exclusion_coords, output_path='white_bg_excluded.jpg'):\n",
        "    # Load image\n",
        "    image = cv2.imread(\"Paste Path here\")\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Adaptive threshold to get foreground (text, images)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, blockSize=15, C=10)\n",
        "\n",
        "    # Dilate to cover thicker content\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    foreground_mask = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    # Invert to get background mask\n",
        "    background_mask = cv2.bitwise_not(foreground_mask)\n",
        "    background_mask_3ch = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Replace background with white\n",
        "    white_bg = np.full_like(image, 255)\n",
        "    cleaned_image = np.where(background_mask_3ch == 255, white_bg, image)\n",
        "\n",
        "    # Exclude defined region (paste original content back)\n",
        "    x, y, w, h = exclusion_coords\n",
        "    cleaned_image[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Save result\n",
        "    cv2.imwrite(output_path, cleaned_image)\n",
        "    print(f\"[+] White background (with preserved region) saved as: {output_path}\")\n",
        "\n",
        "# ----------- Usage -----------\n",
        "# Replace with your image path and region to protect (x, y, width, height)\n",
        "# currently pasted for the test images\n",
        "whiten_background_with_exclusion(\"your_result_card.jpg\", exclusion_coords=(2059, 0, 391, 574))\n"
      ],
      "metadata": {
        "id": "KxMsgmeRuV8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
